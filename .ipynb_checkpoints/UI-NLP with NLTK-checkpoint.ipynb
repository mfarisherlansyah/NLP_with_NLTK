{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING STARTED WITH NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'propbank.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "print(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]:\n",
    "    print(word, sep = ' ', end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = \"\"\"According to the father of Artificial Intelligence, John McCarthy, it is “The science and engineering of making intelligent machines, especially intelligent computer programs”.\n",
    "\n",
    "Artificial Intelligence is a way of making a computer, a computer-controlled robot, or a software think intelligently, in the similar manner the intelligent humans think.\n",
    "\n",
    "AI is accomplished by studying how human brain thinks, and how humans learn, decide, and work while trying to solve a problem, and then using the outcomes of this study as a basis of developing intelligent software and systems.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the father of Artificial Intelligence, John McCarthy, it is “The science and engineering of making intelligent machines, especially intelligent computer programs”.\n",
      "\n",
      "Artificial Intelligence is a way of making a computer, a computer-controlled robot, or a software think intelligently, in the similar manner the intelligent humans think.\n",
      "\n",
      "AI is accomplished by studying how human brain thinks, and how humans learn, decide, and work while trying to solve a problem, and then using the outcomes of this study as a basis of developing intelligent software and systems.\n"
     ]
    }
   ],
   "source": [
    "print(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['According', 'to', 'the', 'father', 'of', 'Artificial', 'Intelligence', ',', 'John', 'McCarthy', ',', 'it', 'is', '“', 'The', 'science', 'and', 'engineering', 'of', 'making', 'intelligent', 'machines', ',', 'especially', 'intelligent', 'computer', 'programs', '”', '.', 'Artificial', 'Intelligence', 'is', 'a', 'way', 'of', 'making', 'a', 'computer', ',', 'a', 'computer-controlled', 'robot', ',', 'or', 'a', 'software', 'think', 'intelligently', ',', 'in', 'the', 'similar', 'manner', 'the', 'intelligent', 'humans', 'think', '.', 'AI', 'is', 'accomplished', 'by', 'studying', 'how', 'human', 'brain', 'thinks', ',', 'and', 'how', 'humans', 'learn', ',', 'decide', ',', 'and', 'work', 'while', 'trying', 'to', 'solve', 'a', 'problem', ',', 'and', 'then', 'using', 'the', 'outcomes', 'of', 'this', 'study', 'as', 'a', 'basis', 'of', 'developing', 'intelligent', 'software', 'and', 'systems', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "AI_tokens = word_tokenize(AI)\n",
    "print(AI_tokens)\n",
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 60 samples and 102 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist()\n",
    "for word in AI_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 10),\n",
       " ('a', 6),\n",
       " ('the', 5),\n",
       " ('of', 5),\n",
       " ('and', 5),\n",
       " ('intelligent', 4),\n",
       " ('is', 3),\n",
       " ('.', 3),\n",
       " ('to', 2),\n",
       " ('artificial', 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import blankline_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_blank = blankline_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'and', 'most', 'beautiful', 'things', 'in', 'the', 'world', 'can', 'not', 'be', 'seen', 'or', 'even', 'touched', ',', 'they', 'must', 'be', 'felt', 'with', 'heart'] \n",
      " 23\n",
      "[('The', 'best'), ('best', 'and'), ('and', 'most'), ('most', 'beautiful'), ('beautiful', 'things'), ('things', 'in'), ('in', 'the'), ('the', 'world'), ('world', 'can'), ('can', 'not'), ('not', 'be'), ('be', 'seen'), ('seen', 'or'), ('or', 'even'), ('even', 'touched'), ('touched', ','), (',', 'they'), ('they', 'must'), ('must', 'be'), ('be', 'felt'), ('felt', 'with'), ('with', 'heart')] \n",
      " 22\n",
      "[('The', 'best', 'and'), ('best', 'and', 'most'), ('and', 'most', 'beautiful'), ('most', 'beautiful', 'things'), ('beautiful', 'things', 'in'), ('things', 'in', 'the'), ('in', 'the', 'world'), ('the', 'world', 'can'), ('world', 'can', 'not'), ('can', 'not', 'be'), ('not', 'be', 'seen'), ('be', 'seen', 'or'), ('seen', 'or', 'even'), ('or', 'even', 'touched'), ('even', 'touched', ','), ('touched', ',', 'they'), (',', 'they', 'must'), ('they', 'must', 'be'), ('must', 'be', 'felt'), ('be', 'felt', 'with'), ('felt', 'with', 'heart')] \n",
      " 21\n",
      "[('The', 'best', 'and', 'most', 'beautiful'), ('best', 'and', 'most', 'beautiful', 'things'), ('and', 'most', 'beautiful', 'things', 'in'), ('most', 'beautiful', 'things', 'in', 'the'), ('beautiful', 'things', 'in', 'the', 'world'), ('things', 'in', 'the', 'world', 'can'), ('in', 'the', 'world', 'can', 'not'), ('the', 'world', 'can', 'not', 'be'), ('world', 'can', 'not', 'be', 'seen'), ('can', 'not', 'be', 'seen', 'or'), ('not', 'be', 'seen', 'or', 'even'), ('be', 'seen', 'or', 'even', 'touched'), ('seen', 'or', 'even', 'touched', ','), ('or', 'even', 'touched', ',', 'they'), ('even', 'touched', ',', 'they', 'must'), ('touched', ',', 'they', 'must', 'be'), (',', 'they', 'must', 'be', 'felt'), ('they', 'must', 'be', 'felt', 'with'), ('must', 'be', 'felt', 'with', 'heart')] \n",
      " 19\n"
     ]
    }
   ],
   "source": [
    "string = \"The best and most beautiful things in the world cannot be seen or even touched, they must be felt with heart\"\n",
    "quotes_tokens = nltk.word_tokenize(string)\n",
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))\n",
    "\n",
    "print(quotes_tokens, \"\\n\", len(quotes_tokens))\n",
    "print(quotes_bigrams, \"\\n\", len(quotes_bigrams))\n",
    "print(quotes_trigrams, \"\\n\", len(quotes_trigrams))\n",
    "print(quotes_ngrams, \"\\n\", len(quotes_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'post-World', 'War', 'II', 'publications', 'of', 'this', 'directory', 'and', 'in', 'other', 'Soviet', 'cookery', 'books', ',', 'such', 'as', 'Cookery', '(', '1955', ')', ',', 'the', \"'Kiev-style\", \"'\", 'name', 'was', 'retained', ',', 'but', 'the', 'terms', 'de', 'volaille', 'and', 'à', 'la', 'Maréchale', 'were', 'indeed', 'dropped', 'in', 'favour', 'of', 'simple', 'names', 'such', 'as', \"'chicken\", 'cutlet', 'stuffed', 'with', 'milk', 'sauce', \"'\", 'and', \"'chicken\", 'cutlet', 'stuffed', 'with', 'liver', \"'\"] \n",
      " 62\n",
      "[('In', 'post-World'), ('post-World', 'War'), ('War', 'II'), ('II', 'publications'), ('publications', 'of'), ('of', 'this'), ('this', 'directory'), ('directory', 'and'), ('and', 'in'), ('in', 'other'), ('other', 'Soviet'), ('Soviet', 'cookery'), ('cookery', 'books'), ('books', ','), (',', 'such'), ('such', 'as'), ('as', 'Cookery'), ('Cookery', '('), ('(', '1955'), ('1955', ')'), (')', ','), (',', 'the'), ('the', \"'Kiev-style\"), (\"'Kiev-style\", \"'\"), (\"'\", 'name'), ('name', 'was'), ('was', 'retained'), ('retained', ','), (',', 'but'), ('but', 'the'), ('the', 'terms'), ('terms', 'de'), ('de', 'volaille'), ('volaille', 'and'), ('and', 'à'), ('à', 'la'), ('la', 'Maréchale'), ('Maréchale', 'were'), ('were', 'indeed'), ('indeed', 'dropped'), ('dropped', 'in'), ('in', 'favour'), ('favour', 'of'), ('of', 'simple'), ('simple', 'names'), ('names', 'such'), ('such', 'as'), ('as', \"'chicken\"), (\"'chicken\", 'cutlet'), ('cutlet', 'stuffed'), ('stuffed', 'with'), ('with', 'milk'), ('milk', 'sauce'), ('sauce', \"'\"), (\"'\", 'and'), ('and', \"'chicken\"), (\"'chicken\", 'cutlet'), ('cutlet', 'stuffed'), ('stuffed', 'with'), ('with', 'liver'), ('liver', \"'\")] \n",
      " 61\n",
      "[('In', 'post-World', 'War'), ('post-World', 'War', 'II'), ('War', 'II', 'publications'), ('II', 'publications', 'of'), ('publications', 'of', 'this'), ('of', 'this', 'directory'), ('this', 'directory', 'and'), ('directory', 'and', 'in'), ('and', 'in', 'other'), ('in', 'other', 'Soviet'), ('other', 'Soviet', 'cookery'), ('Soviet', 'cookery', 'books'), ('cookery', 'books', ','), ('books', ',', 'such'), (',', 'such', 'as'), ('such', 'as', 'Cookery'), ('as', 'Cookery', '('), ('Cookery', '(', '1955'), ('(', '1955', ')'), ('1955', ')', ','), (')', ',', 'the'), (',', 'the', \"'Kiev-style\"), ('the', \"'Kiev-style\", \"'\"), (\"'Kiev-style\", \"'\", 'name'), (\"'\", 'name', 'was'), ('name', 'was', 'retained'), ('was', 'retained', ','), ('retained', ',', 'but'), (',', 'but', 'the'), ('but', 'the', 'terms'), ('the', 'terms', 'de'), ('terms', 'de', 'volaille'), ('de', 'volaille', 'and'), ('volaille', 'and', 'à'), ('and', 'à', 'la'), ('à', 'la', 'Maréchale'), ('la', 'Maréchale', 'were'), ('Maréchale', 'were', 'indeed'), ('were', 'indeed', 'dropped'), ('indeed', 'dropped', 'in'), ('dropped', 'in', 'favour'), ('in', 'favour', 'of'), ('favour', 'of', 'simple'), ('of', 'simple', 'names'), ('simple', 'names', 'such'), ('names', 'such', 'as'), ('such', 'as', \"'chicken\"), ('as', \"'chicken\", 'cutlet'), (\"'chicken\", 'cutlet', 'stuffed'), ('cutlet', 'stuffed', 'with'), ('stuffed', 'with', 'milk'), ('with', 'milk', 'sauce'), ('milk', 'sauce', \"'\"), ('sauce', \"'\", 'and'), (\"'\", 'and', \"'chicken\"), ('and', \"'chicken\", 'cutlet'), (\"'chicken\", 'cutlet', 'stuffed'), ('cutlet', 'stuffed', 'with'), ('stuffed', 'with', 'liver'), ('with', 'liver', \"'\")] \n",
      " 60\n",
      "[('In', 'post-World', 'War', 'II', 'publications'), ('post-World', 'War', 'II', 'publications', 'of'), ('War', 'II', 'publications', 'of', 'this'), ('II', 'publications', 'of', 'this', 'directory'), ('publications', 'of', 'this', 'directory', 'and'), ('of', 'this', 'directory', 'and', 'in'), ('this', 'directory', 'and', 'in', 'other'), ('directory', 'and', 'in', 'other', 'Soviet'), ('and', 'in', 'other', 'Soviet', 'cookery'), ('in', 'other', 'Soviet', 'cookery', 'books'), ('other', 'Soviet', 'cookery', 'books', ','), ('Soviet', 'cookery', 'books', ',', 'such'), ('cookery', 'books', ',', 'such', 'as'), ('books', ',', 'such', 'as', 'Cookery'), (',', 'such', 'as', 'Cookery', '('), ('such', 'as', 'Cookery', '(', '1955'), ('as', 'Cookery', '(', '1955', ')'), ('Cookery', '(', '1955', ')', ','), ('(', '1955', ')', ',', 'the'), ('1955', ')', ',', 'the', \"'Kiev-style\"), (')', ',', 'the', \"'Kiev-style\", \"'\"), (',', 'the', \"'Kiev-style\", \"'\", 'name'), ('the', \"'Kiev-style\", \"'\", 'name', 'was'), (\"'Kiev-style\", \"'\", 'name', 'was', 'retained'), (\"'\", 'name', 'was', 'retained', ','), ('name', 'was', 'retained', ',', 'but'), ('was', 'retained', ',', 'but', 'the'), ('retained', ',', 'but', 'the', 'terms'), (',', 'but', 'the', 'terms', 'de'), ('but', 'the', 'terms', 'de', 'volaille'), ('the', 'terms', 'de', 'volaille', 'and'), ('terms', 'de', 'volaille', 'and', 'à'), ('de', 'volaille', 'and', 'à', 'la'), ('volaille', 'and', 'à', 'la', 'Maréchale'), ('and', 'à', 'la', 'Maréchale', 'were'), ('à', 'la', 'Maréchale', 'were', 'indeed'), ('la', 'Maréchale', 'were', 'indeed', 'dropped'), ('Maréchale', 'were', 'indeed', 'dropped', 'in'), ('were', 'indeed', 'dropped', 'in', 'favour'), ('indeed', 'dropped', 'in', 'favour', 'of'), ('dropped', 'in', 'favour', 'of', 'simple'), ('in', 'favour', 'of', 'simple', 'names'), ('favour', 'of', 'simple', 'names', 'such'), ('of', 'simple', 'names', 'such', 'as'), ('simple', 'names', 'such', 'as', \"'chicken\"), ('names', 'such', 'as', \"'chicken\", 'cutlet'), ('such', 'as', \"'chicken\", 'cutlet', 'stuffed'), ('as', \"'chicken\", 'cutlet', 'stuffed', 'with'), (\"'chicken\", 'cutlet', 'stuffed', 'with', 'milk'), ('cutlet', 'stuffed', 'with', 'milk', 'sauce'), ('stuffed', 'with', 'milk', 'sauce', \"'\"), ('with', 'milk', 'sauce', \"'\", 'and'), ('milk', 'sauce', \"'\", 'and', \"'chicken\"), ('sauce', \"'\", 'and', \"'chicken\", 'cutlet'), (\"'\", 'and', \"'chicken\", 'cutlet', 'stuffed'), ('and', \"'chicken\", 'cutlet', 'stuffed', 'with'), (\"'chicken\", 'cutlet', 'stuffed', 'with', 'liver'), ('cutlet', 'stuffed', 'with', 'liver', \"'\")] \n",
      " 58\n"
     ]
    }
   ],
   "source": [
    "string2 = \"In post-World War II publications of this directory and in other Soviet cookery books, such as Cookery (1955), the 'Kiev-style' name was retained, but the terms de volaille and à la Maréchale were indeed dropped in favour of simple names such as 'chicken cutlet stuffed with milk sauce' and 'chicken cutlet stuffed with liver'\"\n",
    "quotes_tokens = nltk.word_tokenize(string2)\n",
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))\n",
    "\n",
    "print(quotes_tokens, \"\\n\", len(quotes_tokens))\n",
    "print(quotes_bigrams, \"\\n\", len(quotes_bigrams))\n",
    "print(quotes_trigrams, \"\\n\", len(quotes_trigrams))\n",
    "print(quotes_ngrams, \"\\n\", len(quotes_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "according to the father of artificial intelligence, john mccarthy, it is “the science and engineering of making intelligent machines, especially intelligent computer programs”.\n",
      "\n",
      "artificial intelligence is a way of making a computer, a computer-controlled robot, or a software think intelligently, in the similar manner the intelligent humans think.\n",
      "\n",
      "ai is accomplished by studying how human brain thinks, and how humans learn, decide, and work while trying to solve a problem, and then using the outcomes of this study as a basis of developing intelligent software and systems.\n",
      "\n",
      " [((',', 'and'), 6), (('artificial', 'intelligence'), 4), (('of', 'making'), 4), (('according', 'to'), 2), (('to', 'the'), 2), (('the', 'father'), 2), (('father', 'of'), 2), (('of', 'artificial'), 2), (('intelligence', ','), 2), ((',', 'john'), 2)]\n"
     ]
    }
   ],
   "source": [
    "fdist2 = FreqDist()\n",
    "\n",
    "AI2 = AI.lower() # Lower cuma punya string\n",
    "\n",
    "quotes_tokens2 = nltk.word_tokenize(AI2)\n",
    "quotes_bigrams2 = list(nltk.bigrams(quotes_tokens2))\n",
    "\n",
    "for word in quotes_bigrams2:\n",
    "    fdist2[word]+=2\n",
    "\n",
    "print(AI2)\n",
    "fdist2_top10 = fdist2.most_common(10)\n",
    "print(\"\\n\",fdist2_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet # Untuk mengetahui asal dari suatu kata. Makanya pakai wordnet. Misalnya gave dari give.\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gone: gone\n",
      "going: going\n",
      "went: went\n"
     ]
    }
   ],
   "source": [
    "# words_to_lemm=[\"give\", \"giving\", \"given\", \"gave\"]\n",
    "words_to_lemm = [\"gone\",\"going\",\"went\"]\n",
    "word_lem = WordNetLemmatizer()\n",
    "for words in words_to_lemm:\n",
    "    print(words + \": \" + word_lem.lemmatize(words)) # Kok nggak berubah? Artinya lemmatizernya mungkin belum bagus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "giving: give\n",
      "given: given\n",
      "gave: gave\n",
      "have\n",
      "speak to report , yang emphas the econom and societ damag caus to hong kong by the protest and urg citizen to 'stand firm and guard our beauti homeland . ' \n",
      "doe\n"
     ]
    }
   ],
   "source": [
    "pst = PorterStemmer()\n",
    "pst.stem(\"having\") # Melakukan stemming dari kata \"having\"\n",
    "words_to_stem = [\"give\",\"giving\",\"given\",\"gave\"]\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" + pst.stem(words))\n",
    "\n",
    "print(pst.stem(\"having\"))\n",
    "\n",
    "sentence2 = \"\"\"Speaking to reporters, Yang emphasized the economic and societal damage caused to Hong Kong by the protests and urged citizens to 'stand firm and guard our beautiful homeland.'\"\"\"\n",
    "\n",
    "sentence_to_stem = nltk.word_tokenize(sentence2)\n",
    "\n",
    "new_sentence2 = \"\"\n",
    "for words in sentence_to_stem:\n",
    "    new_sentence2 += pst.stem(words) + \" \"\n",
    "\n",
    "print(new_sentence2) # Akurasi tidak melulu benar\n",
    "\n",
    "print(pst.stem(\"does\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: giv\n",
      "giving: giv\n",
      "given: giv\n",
      "gave: gav\n",
      "hav\n",
      "speak to report , yang emphas the econom and societ dam caus to hong kong by the protest and urg cit to 'stand firm and guard our beauty homeland . ' \n",
      "doe\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "pst2 = LancasterStemmer()\n",
    "pst2.stem(\"having\") # Melakukan stemming dari kata \"having\"\n",
    "words_to_stem = [\"give\",\"giving\",\"given\",\"gave\"]\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" + pst2.stem(words))\n",
    "\n",
    "print(pst2.stem(\"having\"))\n",
    "\n",
    "sentence2 = \"\"\"Speaking to reporters, Yang emphasized the economic and societal damage caused to Hong Kong by the protests and urged citizens to 'stand firm and guard our beautiful homeland.'\"\"\"\n",
    "\n",
    "sentence_to_stem = nltk.word_tokenize(sentence2)\n",
    "\n",
    "new_sentence2 = \"\"\n",
    "for words in sentence_to_stem:\n",
    "    new_sentence2 += pst2.stem(words) + \" \"\n",
    "\n",
    "print(new_sentence2) # Akurasi tidak melulu benar\n",
    "\n",
    "print(pst2.stem(\"does\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but in it press confer later in the day , beij 's hong kong and macau affair offic focus squar on the econom impact of the protest , make it clear the situat could n't be allow to continu . \n",
      "[('the', 4), ('in', 2), ('it', 2), (',', 2), ('but', 1), ('press', 1), ('confer', 1), ('later', 1), ('day', 1), ('beij', 1), (\"'s\", 1), ('hong', 1), ('kong', 1), ('and', 1), ('macau', 1), ('affair', 1), ('offic', 1), ('focus', 1), ('squar', 1), ('on', 1)]\n"
     ]
    }
   ],
   "source": [
    "pst = PorterStemmer()\n",
    "# pst.stem(\"having\") # Melakukan stemming dari kata \"having\"\n",
    "# words_to_stem = [\"give\",\"giving\",\"given\",\"gave\"]\n",
    "\n",
    "# for words in words_to_stem:\n",
    "#     print(words+ \": \" + pst.stem(words))\n",
    "\n",
    "# print(pst.stem(\"having\"))\n",
    "\n",
    "sentence2 = \"\"\"But in its press conference later in the day, Beijing's Hong Kong and Macau Affairs Office focused squarely on the economic impact of the protests, making it clear the situation couldn't be allowed to continue.\"\"\"\n",
    "sentence_to_stem = nltk.word_tokenize(sentence2)\n",
    "\n",
    "new_sentence2 = \"\"\n",
    "for words in sentence_to_stem:\n",
    "    new_sentence2 += pst.stem(words) + \" \"\n",
    "\n",
    "print(new_sentence2) # Akurasi tidak melulu benar\n",
    "\n",
    "fdist2 = FreqDist()\n",
    "\n",
    "new_sentence21 = nltk.word_tokenize(new_sentence2)\n",
    "\n",
    "for words in new_sentence21:\n",
    "    fdist2[words.lower()]+=1\n",
    "\n",
    "fdist2_top20 = fdist2.most_common(20)\n",
    "print(fdist2_top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-2849d11d81ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_to_stem2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msentence_to_stem2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfdist2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfdist2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence2 = \"\"\"But in its press conference later in the day, Beijing's Hong Kong and Macau Affairs Office focused squarely on the economic impact of the protests, making it clear the situation couldn't be allowed to continue.\"\"\"\n",
    "sentence_to_stem2 = nltk.word_tokenize(sentence2)\n",
    "\n",
    "for words in sentence_to_stem2:\n",
    "    sentence_to_stem2 += pst.stem(words) + \" \"\n",
    "    fdist2[words.lower()]+=1\n",
    "\n",
    "fdist2.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['According',\n",
       " 'to',\n",
       " 'the',\n",
       " 'father',\n",
       " 'of',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'John',\n",
       " 'McCarthy',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " '“',\n",
       " 'The',\n",
       " 'science',\n",
       " 'and',\n",
       " 'engineering',\n",
       " 'of',\n",
       " 'making',\n",
       " 'intelligent',\n",
       " 'machines',\n",
       " ',',\n",
       " 'especially',\n",
       " 'intelligent',\n",
       " 'computer',\n",
       " 'programs',\n",
       " '”',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'a',\n",
       " 'way',\n",
       " 'of',\n",
       " 'making',\n",
       " 'a',\n",
       " 'computer',\n",
       " ',',\n",
       " 'a',\n",
       " 'computercontrolled',\n",
       " 'robot',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'software',\n",
       " 'think',\n",
       " 'intelligently',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'similar',\n",
       " 'manner',\n",
       " 'the',\n",
       " 'intelligent',\n",
       " 'humans',\n",
       " 'think',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'accomplished',\n",
       " 'by',\n",
       " 'studying',\n",
       " 'how',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'thinks',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'humans',\n",
       " 'learn',\n",
       " ',',\n",
       " 'decide',\n",
       " ',',\n",
       " 'and',\n",
       " 'work',\n",
       " 'while',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'a',\n",
       " 'problem',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'using',\n",
       " 'the',\n",
       " 'outcomes',\n",
       " 'of',\n",
       " 'this',\n",
       " 'study',\n",
       " 'as',\n",
       " 'a',\n",
       " 'basis',\n",
       " 'of',\n",
       " 'developing',\n",
       " 'intelligent',\n",
       " 'software',\n",
       " 'and',\n",
       " 'systems']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "punctuation=re.compile(r'[-.?!.:;()|0-9]') # Regular expansion. Maksudnya meng-compile regular expansion. Jika mesin menemukan\n",
    "# karakter-karakter tersebut, maka karakter-karakter tersebut akan ikut dihapus.\n",
    "post_punctuation=[]\n",
    "\n",
    "for words in AI_tokens:\n",
    "    word=punctuation.sub(\"\", words)\n",
    "    if len(word) > 0:\n",
    "        post_punctuation.append(word)\n",
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada',\n",
       " 'adalah',\n",
       " 'adanya',\n",
       " 'adapun',\n",
       " 'agak',\n",
       " 'agaknya',\n",
       " 'agar',\n",
       " 'akan',\n",
       " 'akankah',\n",
       " 'akhir',\n",
       " 'akhiri',\n",
       " 'akhirnya',\n",
       " 'aku',\n",
       " 'akulah',\n",
       " 'amat',\n",
       " 'amatlah',\n",
       " 'anda',\n",
       " 'andalah',\n",
       " 'antar',\n",
       " 'antara',\n",
       " 'antaranya',\n",
       " 'apa',\n",
       " 'apaan',\n",
       " 'apabila',\n",
       " 'apakah',\n",
       " 'apalagi',\n",
       " 'apatah',\n",
       " 'artinya',\n",
       " 'asal',\n",
       " 'asalkan',\n",
       " 'atas',\n",
       " 'atau',\n",
       " 'ataukah',\n",
       " 'ataupun',\n",
       " 'awal',\n",
       " 'awalnya',\n",
       " 'bagai',\n",
       " 'bagaikan',\n",
       " 'bagaimana',\n",
       " 'bagaimanakah',\n",
       " 'bagaimanapun',\n",
       " 'bagi',\n",
       " 'bagian',\n",
       " 'bahkan',\n",
       " 'bahwa',\n",
       " 'bahwasanya',\n",
       " 'baik',\n",
       " 'bakal',\n",
       " 'bakalan',\n",
       " 'balik',\n",
       " 'banyak',\n",
       " 'bapak',\n",
       " 'baru',\n",
       " 'bawah',\n",
       " 'beberapa',\n",
       " 'begini',\n",
       " 'beginian',\n",
       " 'beginikah',\n",
       " 'beginilah',\n",
       " 'begitu',\n",
       " 'begitukah',\n",
       " 'begitulah',\n",
       " 'begitupun',\n",
       " 'bekerja',\n",
       " 'belakang',\n",
       " 'belakangan',\n",
       " 'belum',\n",
       " 'belumlah',\n",
       " 'benar',\n",
       " 'benarkah',\n",
       " 'benarlah',\n",
       " 'berada',\n",
       " 'berakhir',\n",
       " 'berakhirlah',\n",
       " 'berakhirnya',\n",
       " 'berapa',\n",
       " 'berapakah',\n",
       " 'berapalah',\n",
       " 'berapapun',\n",
       " 'berarti',\n",
       " 'berawal',\n",
       " 'berbagai',\n",
       " 'berdatangan',\n",
       " 'beri',\n",
       " 'berikan',\n",
       " 'berikut',\n",
       " 'berikutnya',\n",
       " 'berjumlah',\n",
       " 'berkali-kali',\n",
       " 'berkata',\n",
       " 'berkehendak',\n",
       " 'berkeinginan',\n",
       " 'berkenaan',\n",
       " 'berlainan',\n",
       " 'berlalu',\n",
       " 'berlangsung',\n",
       " 'berlebihan',\n",
       " 'bermacam',\n",
       " 'bermacam-macam',\n",
       " 'bermaksud',\n",
       " 'bermula',\n",
       " 'bersama',\n",
       " 'bersama-sama',\n",
       " 'bersiap',\n",
       " 'bersiap-siap',\n",
       " 'bertanya',\n",
       " 'bertanya-tanya',\n",
       " 'berturut',\n",
       " 'berturut-turut',\n",
       " 'bertutur',\n",
       " 'berujar',\n",
       " 'berupa',\n",
       " 'besar',\n",
       " 'betul',\n",
       " 'betulkah',\n",
       " 'biasa',\n",
       " 'biasanya',\n",
       " 'bila',\n",
       " 'bilakah',\n",
       " 'bisa',\n",
       " 'bisakah',\n",
       " 'boleh',\n",
       " 'bolehkah',\n",
       " 'bolehlah',\n",
       " 'buat',\n",
       " 'bukan',\n",
       " 'bukankah',\n",
       " 'bukanlah',\n",
       " 'bukannya',\n",
       " 'bulan',\n",
       " 'bung',\n",
       " 'cara',\n",
       " 'caranya',\n",
       " 'cukup',\n",
       " 'cukupkah',\n",
       " 'cukuplah',\n",
       " 'cuma',\n",
       " 'dahulu',\n",
       " 'dalam',\n",
       " 'dan',\n",
       " 'dapat',\n",
       " 'dari',\n",
       " 'daripada',\n",
       " 'datang',\n",
       " 'dekat',\n",
       " 'demi',\n",
       " 'demikian',\n",
       " 'demikianlah',\n",
       " 'dengan',\n",
       " 'depan',\n",
       " 'di',\n",
       " 'dia',\n",
       " 'diakhiri',\n",
       " 'diakhirinya',\n",
       " 'dialah',\n",
       " 'diantara',\n",
       " 'diantaranya',\n",
       " 'diberi',\n",
       " 'diberikan',\n",
       " 'diberikannya',\n",
       " 'dibuat',\n",
       " 'dibuatnya',\n",
       " 'didapat',\n",
       " 'didatangkan',\n",
       " 'digunakan',\n",
       " 'diibaratkan',\n",
       " 'diibaratkannya',\n",
       " 'diingat',\n",
       " 'diingatkan',\n",
       " 'diinginkan',\n",
       " 'dijawab',\n",
       " 'dijelaskan',\n",
       " 'dijelaskannya',\n",
       " 'dikarenakan',\n",
       " 'dikatakan',\n",
       " 'dikatakannya',\n",
       " 'dikerjakan',\n",
       " 'diketahui',\n",
       " 'diketahuinya',\n",
       " 'dikira',\n",
       " 'dilakukan',\n",
       " 'dilalui',\n",
       " 'dilihat',\n",
       " 'dimaksud',\n",
       " 'dimaksudkan',\n",
       " 'dimaksudkannya',\n",
       " 'dimaksudnya',\n",
       " 'diminta',\n",
       " 'dimintai',\n",
       " 'dimisalkan',\n",
       " 'dimulai',\n",
       " 'dimulailah',\n",
       " 'dimulainya',\n",
       " 'dimungkinkan',\n",
       " 'dini',\n",
       " 'dipastikan',\n",
       " 'diperbuat',\n",
       " 'diperbuatnya',\n",
       " 'dipergunakan',\n",
       " 'diperkirakan',\n",
       " 'diperlihatkan',\n",
       " 'diperlukan',\n",
       " 'diperlukannya',\n",
       " 'dipersoalkan',\n",
       " 'dipertanyakan',\n",
       " 'dipunyai',\n",
       " 'diri',\n",
       " 'dirinya',\n",
       " 'disampaikan',\n",
       " 'disebut',\n",
       " 'disebutkan',\n",
       " 'disebutkannya',\n",
       " 'disini',\n",
       " 'disinilah',\n",
       " 'ditambahkan',\n",
       " 'ditandaskan',\n",
       " 'ditanya',\n",
       " 'ditanyai',\n",
       " 'ditanyakan',\n",
       " 'ditegaskan',\n",
       " 'ditujukan',\n",
       " 'ditunjuk',\n",
       " 'ditunjuki',\n",
       " 'ditunjukkan',\n",
       " 'ditunjukkannya',\n",
       " 'ditunjuknya',\n",
       " 'dituturkan',\n",
       " 'dituturkannya',\n",
       " 'diucapkan',\n",
       " 'diucapkannya',\n",
       " 'diungkapkan',\n",
       " 'dong',\n",
       " 'dua',\n",
       " 'dulu',\n",
       " 'empat',\n",
       " 'enggak',\n",
       " 'enggaknya',\n",
       " 'entah',\n",
       " 'entahlah',\n",
       " 'guna',\n",
       " 'gunakan',\n",
       " 'hal',\n",
       " 'hampir',\n",
       " 'hanya',\n",
       " 'hanyalah',\n",
       " 'hari',\n",
       " 'harus',\n",
       " 'haruslah',\n",
       " 'harusnya',\n",
       " 'hendak',\n",
       " 'hendaklah',\n",
       " 'hendaknya',\n",
       " 'hingga',\n",
       " 'ia',\n",
       " 'ialah',\n",
       " 'ibarat',\n",
       " 'ibaratkan',\n",
       " 'ibaratnya',\n",
       " 'ibu',\n",
       " 'ikut',\n",
       " 'ingat',\n",
       " 'ingat-ingat',\n",
       " 'ingin',\n",
       " 'inginkah',\n",
       " 'inginkan',\n",
       " 'ini',\n",
       " 'inikah',\n",
       " 'inilah',\n",
       " 'itu',\n",
       " 'itukah',\n",
       " 'itulah',\n",
       " 'jadi',\n",
       " 'jadilah',\n",
       " 'jadinya',\n",
       " 'jangan',\n",
       " 'jangankan',\n",
       " 'janganlah',\n",
       " 'jauh',\n",
       " 'jawab',\n",
       " 'jawaban',\n",
       " 'jawabnya',\n",
       " 'jelas',\n",
       " 'jelaskan',\n",
       " 'jelaslah',\n",
       " 'jelasnya',\n",
       " 'jika',\n",
       " 'jikalau',\n",
       " 'juga',\n",
       " 'jumlah',\n",
       " 'jumlahnya',\n",
       " 'justru',\n",
       " 'kala',\n",
       " 'kalau',\n",
       " 'kalaulah',\n",
       " 'kalaupun',\n",
       " 'kalian',\n",
       " 'kami',\n",
       " 'kamilah',\n",
       " 'kamu',\n",
       " 'kamulah',\n",
       " 'kan',\n",
       " 'kapan',\n",
       " 'kapankah',\n",
       " 'kapanpun',\n",
       " 'karena',\n",
       " 'karenanya',\n",
       " 'kasus',\n",
       " 'kata',\n",
       " 'katakan',\n",
       " 'katakanlah',\n",
       " 'katanya',\n",
       " 'ke',\n",
       " 'keadaan',\n",
       " 'kebetulan',\n",
       " 'kecil',\n",
       " 'kedua',\n",
       " 'keduanya',\n",
       " 'keinginan',\n",
       " 'kelamaan',\n",
       " 'kelihatan',\n",
       " 'kelihatannya',\n",
       " 'kelima',\n",
       " 'keluar',\n",
       " 'kembali',\n",
       " 'kemudian',\n",
       " 'kemungkinan',\n",
       " 'kemungkinannya',\n",
       " 'kenapa',\n",
       " 'kepada',\n",
       " 'kepadanya',\n",
       " 'kesampaian',\n",
       " 'keseluruhan',\n",
       " 'keseluruhannya',\n",
       " 'keterlaluan',\n",
       " 'ketika',\n",
       " 'khususnya',\n",
       " 'kini',\n",
       " 'kinilah',\n",
       " 'kira',\n",
       " 'kira-kira',\n",
       " 'kiranya',\n",
       " 'kita',\n",
       " 'kitalah',\n",
       " 'kok',\n",
       " 'kurang',\n",
       " 'lagi',\n",
       " 'lagian',\n",
       " 'lah',\n",
       " 'lain',\n",
       " 'lainnya',\n",
       " 'lalu',\n",
       " 'lama',\n",
       " 'lamanya',\n",
       " 'lanjut',\n",
       " 'lanjutnya',\n",
       " 'lebih',\n",
       " 'lewat',\n",
       " 'lima',\n",
       " 'luar',\n",
       " 'macam',\n",
       " 'maka',\n",
       " 'makanya',\n",
       " 'makin',\n",
       " 'malah',\n",
       " 'malahan',\n",
       " 'mampu',\n",
       " 'mampukah',\n",
       " 'mana',\n",
       " 'manakala',\n",
       " 'manalagi',\n",
       " 'masa',\n",
       " 'masalah',\n",
       " 'masalahnya',\n",
       " 'masih',\n",
       " 'masihkah',\n",
       " 'masing',\n",
       " 'masing-masing',\n",
       " 'mau',\n",
       " 'maupun',\n",
       " 'melainkan',\n",
       " 'melakukan',\n",
       " 'melalui',\n",
       " 'melihat',\n",
       " 'melihatnya',\n",
       " 'memang',\n",
       " 'memastikan',\n",
       " 'memberi',\n",
       " 'memberikan',\n",
       " 'membuat',\n",
       " 'memerlukan',\n",
       " 'memihak',\n",
       " 'meminta',\n",
       " 'memintakan',\n",
       " 'memisalkan',\n",
       " 'memperbuat',\n",
       " 'mempergunakan',\n",
       " 'memperkirakan',\n",
       " 'memperlihatkan',\n",
       " 'mempersiapkan',\n",
       " 'mempersoalkan',\n",
       " 'mempertanyakan',\n",
       " 'mempunyai',\n",
       " 'memulai',\n",
       " 'memungkinkan',\n",
       " 'menaiki',\n",
       " 'menambahkan',\n",
       " 'menandaskan',\n",
       " 'menanti',\n",
       " 'menanti-nanti',\n",
       " 'menantikan',\n",
       " 'menanya',\n",
       " 'menanyai',\n",
       " 'menanyakan',\n",
       " 'mendapat',\n",
       " 'mendapatkan',\n",
       " 'mendatang',\n",
       " 'mendatangi',\n",
       " 'mendatangkan',\n",
       " 'menegaskan',\n",
       " 'mengakhiri',\n",
       " 'mengapa',\n",
       " 'mengatakan',\n",
       " 'mengatakannya',\n",
       " 'mengenai',\n",
       " 'mengerjakan',\n",
       " 'mengetahui',\n",
       " 'menggunakan',\n",
       " 'menghendaki',\n",
       " 'mengibaratkan',\n",
       " 'mengibaratkannya',\n",
       " 'mengingat',\n",
       " 'mengingatkan',\n",
       " 'menginginkan',\n",
       " 'mengira',\n",
       " 'mengucapkan',\n",
       " 'mengucapkannya',\n",
       " 'mengungkapkan',\n",
       " 'menjadi',\n",
       " 'menjawab',\n",
       " 'menjelaskan',\n",
       " 'menuju',\n",
       " 'menunjuk',\n",
       " 'menunjuki',\n",
       " 'menunjukkan',\n",
       " 'menunjuknya',\n",
       " 'menurut',\n",
       " 'menuturkan',\n",
       " 'menyampaikan',\n",
       " 'menyangkut',\n",
       " 'menyatakan',\n",
       " 'menyebutkan',\n",
       " 'menyeluruh',\n",
       " 'menyiapkan',\n",
       " 'merasa',\n",
       " 'mereka',\n",
       " 'merekalah',\n",
       " 'merupakan',\n",
       " 'meski',\n",
       " 'meskipun',\n",
       " 'meyakini',\n",
       " 'meyakinkan',\n",
       " 'minta',\n",
       " 'mirip',\n",
       " 'misal',\n",
       " 'misalkan',\n",
       " 'misalnya',\n",
       " 'mula',\n",
       " 'mulai',\n",
       " 'mulailah',\n",
       " 'mulanya',\n",
       " 'mungkin',\n",
       " 'mungkinkah',\n",
       " 'nah',\n",
       " 'naik',\n",
       " 'namun',\n",
       " 'nanti',\n",
       " 'nantinya',\n",
       " 'nyaris',\n",
       " 'nyatanya',\n",
       " 'oleh',\n",
       " 'olehnya',\n",
       " 'pada',\n",
       " 'padahal',\n",
       " 'padanya',\n",
       " 'pak',\n",
       " 'paling',\n",
       " 'panjang',\n",
       " 'pantas',\n",
       " 'para',\n",
       " 'pasti',\n",
       " 'pastilah',\n",
       " 'penting',\n",
       " 'pentingnya',\n",
       " 'per',\n",
       " 'percuma',\n",
       " 'perlu',\n",
       " 'perlukah',\n",
       " 'perlunya',\n",
       " 'pernah',\n",
       " 'persoalan',\n",
       " 'pertama',\n",
       " 'pertama-tama',\n",
       " 'pertanyaan',\n",
       " 'pertanyakan',\n",
       " 'pihak',\n",
       " 'pihaknya',\n",
       " 'pukul',\n",
       " 'pula',\n",
       " 'pun',\n",
       " 'punya',\n",
       " 'rasa',\n",
       " 'rasanya',\n",
       " 'rata',\n",
       " 'rupanya',\n",
       " 'saat',\n",
       " 'saatnya',\n",
       " 'saja',\n",
       " 'sajalah',\n",
       " 'saling',\n",
       " 'sama',\n",
       " 'sama-sama',\n",
       " 'sambil',\n",
       " 'sampai',\n",
       " 'sampai-sampai',\n",
       " 'sampaikan',\n",
       " 'sana',\n",
       " 'sangat',\n",
       " 'sangatlah',\n",
       " 'satu',\n",
       " 'saya',\n",
       " 'sayalah',\n",
       " 'se',\n",
       " 'sebab',\n",
       " 'sebabnya',\n",
       " 'sebagai',\n",
       " 'sebagaimana',\n",
       " 'sebagainya',\n",
       " 'sebagian',\n",
       " 'sebaik',\n",
       " 'sebaik-baiknya',\n",
       " 'sebaiknya',\n",
       " 'sebaliknya',\n",
       " 'sebanyak',\n",
       " 'sebegini',\n",
       " 'sebegitu',\n",
       " 'sebelum',\n",
       " 'sebelumnya',\n",
       " 'sebenarnya',\n",
       " 'seberapa',\n",
       " 'sebesar',\n",
       " 'sebetulnya',\n",
       " 'sebisanya',\n",
       " 'sebuah',\n",
       " 'sebut',\n",
       " 'sebutlah',\n",
       " 'sebutnya',\n",
       " 'secara',\n",
       " 'secukupnya',\n",
       " 'sedang',\n",
       " 'sedangkan',\n",
       " 'sedemikian',\n",
       " 'sedikit',\n",
       " 'sedikitnya',\n",
       " 'seenaknya',\n",
       " 'segala',\n",
       " 'segalanya',\n",
       " 'segera',\n",
       " 'seharusnya',\n",
       " 'sehingga',\n",
       " 'seingat',\n",
       " 'sejak',\n",
       " 'sejauh',\n",
       " 'sejenak',\n",
       " 'sejumlah',\n",
       " 'sekadar',\n",
       " 'sekadarnya',\n",
       " 'sekali',\n",
       " 'sekali-kali',\n",
       " 'sekalian',\n",
       " 'sekaligus',\n",
       " 'sekalipun',\n",
       " 'sekarang',\n",
       " 'sekarang',\n",
       " 'sekecil',\n",
       " 'seketika',\n",
       " 'sekiranya',\n",
       " 'sekitar',\n",
       " 'sekitarnya',\n",
       " 'sekurang-kurangnya',\n",
       " 'sekurangnya',\n",
       " 'sela',\n",
       " 'selain',\n",
       " 'selaku',\n",
       " 'selalu',\n",
       " 'selama',\n",
       " 'selama-lamanya',\n",
       " 'selamanya',\n",
       " 'selanjutnya',\n",
       " 'seluruh',\n",
       " 'seluruhnya',\n",
       " 'semacam',\n",
       " 'semakin',\n",
       " 'semampu',\n",
       " 'semampunya',\n",
       " 'semasa',\n",
       " 'semasih',\n",
       " 'semata',\n",
       " 'semata-mata',\n",
       " 'semaunya',\n",
       " 'sementara',\n",
       " 'semisal',\n",
       " 'semisalnya',\n",
       " 'sempat',\n",
       " 'semua',\n",
       " 'semuanya',\n",
       " 'semula',\n",
       " 'sendiri',\n",
       " 'sendirian',\n",
       " 'sendirinya',\n",
       " 'seolah',\n",
       " 'seolah-olah',\n",
       " 'seorang',\n",
       " 'sepanjang',\n",
       " 'sepantasnya',\n",
       " 'sepantasnyalah',\n",
       " 'seperlunya',\n",
       " 'seperti',\n",
       " 'sepertinya',\n",
       " 'sepihak',\n",
       " 'sering',\n",
       " 'seringnya',\n",
       " 'serta',\n",
       " 'serupa',\n",
       " 'sesaat',\n",
       " 'sesama',\n",
       " 'sesampai',\n",
       " 'sesegera',\n",
       " 'sesekali',\n",
       " 'seseorang',\n",
       " 'sesuatu',\n",
       " 'sesuatunya',\n",
       " 'sesudah',\n",
       " 'sesudahnya',\n",
       " 'setelah',\n",
       " 'setempat',\n",
       " 'setengah',\n",
       " 'seterusnya',\n",
       " 'setiap',\n",
       " 'setiba',\n",
       " 'setibanya',\n",
       " 'setidak-tidaknya',\n",
       " 'setidaknya',\n",
       " 'setinggi',\n",
       " 'seusai',\n",
       " 'sewaktu',\n",
       " 'siap',\n",
       " 'siapa',\n",
       " 'siapakah',\n",
       " 'siapapun',\n",
       " 'sini',\n",
       " 'sinilah',\n",
       " 'soal',\n",
       " 'soalnya',\n",
       " 'suatu',\n",
       " 'sudah',\n",
       " 'sudahkah',\n",
       " 'sudahlah',\n",
       " 'supaya',\n",
       " 'tadi',\n",
       " 'tadinya',\n",
       " 'tahu',\n",
       " 'tahun',\n",
       " 'tak',\n",
       " 'tambah',\n",
       " 'tambahnya',\n",
       " 'tampak',\n",
       " 'tampaknya',\n",
       " 'tandas',\n",
       " 'tandasnya',\n",
       " 'tanpa',\n",
       " 'tanya',\n",
       " 'tanyakan',\n",
       " 'tanyanya',\n",
       " 'tapi',\n",
       " 'tegas',\n",
       " 'tegasnya',\n",
       " 'telah',\n",
       " 'tempat',\n",
       " 'tengah',\n",
       " 'tentang',\n",
       " 'tentu',\n",
       " 'tentulah',\n",
       " 'tentunya',\n",
       " 'tepat',\n",
       " 'terakhir',\n",
       " 'terasa',\n",
       " 'terbanyak',\n",
       " 'terdahulu',\n",
       " 'terdapat',\n",
       " 'terdiri',\n",
       " 'terhadap',\n",
       " 'terhadapnya',\n",
       " 'teringat',\n",
       " 'teringat-ingat',\n",
       " 'terjadi',\n",
       " 'terjadilah',\n",
       " 'terjadinya',\n",
       " 'terkira',\n",
       " 'terlalu',\n",
       " 'terlebih',\n",
       " 'terlihat',\n",
       " 'termasuk',\n",
       " 'ternyata',\n",
       " 'tersampaikan',\n",
       " 'tersebut',\n",
       " 'tersebutlah',\n",
       " 'tertentu',\n",
       " 'tertuju',\n",
       " 'terus',\n",
       " 'terutama',\n",
       " 'tetap',\n",
       " 'tetapi',\n",
       " 'tiap',\n",
       " 'tiba',\n",
       " 'tiba-tiba',\n",
       " 'tidak',\n",
       " 'tidakkah',\n",
       " 'tidaklah',\n",
       " 'tiga',\n",
       " 'tinggi',\n",
       " 'toh',\n",
       " 'tunjuk',\n",
       " 'turut',\n",
       " 'tutur',\n",
       " 'tuturnya',\n",
       " 'ucap',\n",
       " 'ucapnya',\n",
       " 'ujar',\n",
       " 'ujarnya',\n",
       " 'umum',\n",
       " 'umumnya',\n",
       " 'ungkap',\n",
       " 'ungkapnya',\n",
       " 'untuk',\n",
       " 'usah',\n",
       " 'usai',\n",
       " 'waduh',\n",
       " 'wah',\n",
       " 'wahai',\n",
       " 'waktu',\n",
       " 'waktunya',\n",
       " 'walau',\n",
       " 'walaupun',\n",
       " 'wong',\n",
       " 'yaitu',\n",
       " 'yakin',\n",
       " 'yakni',\n",
       " 'yang']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tuntutan', 'lainnya', 'berturut-turut', 'adalah', 'presiden', 'agar', 'melakukan', 'audit', 'secara', 'menyeluruh', 'terhadap', 'PLN', ',', 'presiden', 'agar', 'merombak', 'Kementerian', 'ESDM', 'dan', 'Kementerian', 'BUMN', ',', 'penunjukan', 'forum', 'atau', 'lembaga', 'independen', 'lain', 'untuk', 'melakukan', 'distribusi', 'kepada', 'seluruh', 'pelanggan', 'PLN', '.'] \n",
      "\n",
      "['Tuntutan', 'presiden', 'audit', 'PLN', ',', 'presiden', 'merombak', 'Kementerian', 'ESDM', 'Kementerian', 'BUMN', ',', 'penunjukan', 'forum', 'lembaga', 'independen', 'distribusi', 'pelanggan', 'PLN', '.'] \n",
      "\n",
      "758\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import re\n",
    "punctuation=re.compile(r'[-.?!.:;()|0-9]')\n",
    "post_punctuation=[]\n",
    "\n",
    "example_sent = \"Tuntutan lainnya berturut-turut adalah presiden agar melakukan audit secara menyeluruh terhadap PLN, presiden agar merombak Kementerian ESDM dan Kementerian BUMN, penunjukan forum atau lembaga independen lain untuk melakukan distribusi kepada seluruh pelanggan PLN.\"\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "# for words in word_tokens:\n",
    "#     word=punctuation.sub(\"\", words)\n",
    "#     if len(word) > 0:\n",
    "#         post_punctuation.append(word)\n",
    "\n",
    "# print(post_punctuation)\n",
    "\n",
    "stop_words = set(stopwords.words('indonesian')) \n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if w not in stop_words] \n",
    "  \n",
    "filtered_sentence = [] \n",
    "\n",
    "for w in word_tokens: \n",
    "     if w not in stop_words: \n",
    "         filtered_sentence.append(w) \n",
    "  \n",
    "print(word_tokens, \"\\n\") \n",
    "print(filtered_sentence, \"\\n\")\n",
    "\n",
    "print(len(stopwords.words('indonesian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', ':', \"'\", '\"', 'ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara', 'antaranya', 'apa', 'apaan', 'apabila', 'apakah', 'apalagi', 'apatah', 'artinya', 'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal', 'awalnya', 'bagai', 'bagaikan', 'bagaimana', 'bagaimanakah', 'bagaimanapun', 'bagi', 'bagian', 'bahkan', 'bahwa', 'bahwasanya', 'baik', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah', 'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah', 'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah', 'benar', 'benarkah', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya', 'berapa', 'berapakah', 'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'beri', 'berikan', 'berikut', 'berikutnya', 'berjumlah', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan', 'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam', 'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap', 'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar', 'berupa', 'besar', 'betul', 'betulkah', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'bisakah', 'boleh', 'bolehkah', 'bolehlah', 'buat', 'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'cara', 'caranya', 'cukup', 'cukupkah', 'cukuplah', 'cuma', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi', 'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya', 'dialah', 'diantara', 'diantaranya', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat', 'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan', 'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan', 'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan', 'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah', 'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan', 'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan', 'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebut', 'disebutkan', 'disebutkannya', 'disini', 'disinilah', 'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk', 'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan', 'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'empat', 'enggak', 'enggaknya', 'entah', 'entahlah', 'guna', 'gunakan', 'hal', 'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'hendak', 'hendaklah', 'hendaknya', 'hingga', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut', 'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban', 'jawabnya', 'jelas', 'jelaskan', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kalian', 'kami', 'kamilah', 'kamu', 'kamulah', 'kan', 'kapan', 'kapankah', 'kapanpun', 'karena', 'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya', 'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan', 'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kenapa', 'kepada', 'kepadanya', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'lalu', 'lama', 'lamanya', 'lanjut', 'lanjutnya', 'lebih', 'lewat', 'lima', 'luar', 'macam', 'maka', 'makanya', 'makin', 'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya', 'masih', 'masihkah', 'masing', 'masing-masing', 'mau', 'maupun', 'melainkan', 'melakukan', 'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat', 'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan', 'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai', 'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti', 'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi', 'mendatangkan', 'menegaskan', 'mengakhiri', 'mengapa', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan', 'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan', 'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab', 'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjukkan', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan', 'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah', 'merupakan', 'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'nah', 'naik', 'namun', 'nanti', 'nantinya', 'nyaris', 'nyatanya', 'oleh', 'olehnya', 'pada', 'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting', 'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama', 'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'rasa', 'rasanya', 'rata', 'rupanya', 'saat', 'saatnya', 'saja', 'sajalah', 'saling', 'sama', 'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian', 'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum', 'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', 'sebut', 'sebutlah', 'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya', 'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah', 'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela', 'selagi', 'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya', 'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya', 'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian', 'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya', 'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai', 'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat', 'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai', 'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', 'sudahkah', 'sudahlah', 'supaya', 'tadi', 'tadinya', 'tahu', 'tahun', 'tak', 'tambah', 'tambahnya', 'tampak', 'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya', 'telah', 'tempat', 'tengah', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak', 'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi', 'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan', 'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba', 'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'tinggi', 'toh', 'tunjuk', 'turut', 'tutur', 'tuturnya', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umum', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'waduh', 'wah', 'wahai', 'waktu', 'waktunya', 'walau', 'walaupun', 'wong', 'yaitu', 'yakin', 'yakni', 'yang'] \n",
      "\n",
      "['tuntutan', 'lainnya', 'berturut-turut', 'adalah', 'presiden', 'agar', 'melakukan', 'audit', 'secara', 'menyeluruh', 'terhadap', 'pln', ',', 'presiden', 'agar', 'merombak', 'kementerian', 'esdm', 'dan', 'kementerian', 'bumn', ',', 'penunjukan', 'forum', 'atau', 'lembaga', 'independen', 'lain', 'untuk', 'melakukan', 'distribusi', 'kepada', 'seluruh', 'pelanggan', 'pln', '.'] \n",
      "\n",
      "['tuntutan', 'presiden', 'audit', 'pln', 'presiden', 'merombak', 'kementerian', 'esdm', 'kementerian', 'bumn', 'penunjukan', 'forum', 'lembaga', 'independen', 'distribusi', 'pelanggan', 'pln'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"stopwords-id.txt\") # Ambil data\n",
    "stopwordsbaru = [stopword.strip() for stopword in fo.readlines()]\n",
    "print(stopwordsbaru, \"\\n\")\n",
    "\n",
    "example_sent_tokens = nltk.word_tokenize(example_sent.lower()) # Tokenize sekalian dibikin jadi lowercase\n",
    "print(example_sent_tokens, \"\\n\")\n",
    "\n",
    "cleaner_sentence = [sen for sen in example_sent_tokens if not sen in stopwordsbaru]\n",
    "\n",
    "# cleaner_sentence = []\n",
    "\n",
    "# for sen in example_sent_tokens:\n",
    "#     if sen not in stopwordsbaru:\n",
    "#         cleaner_sentence.append(sen)\n",
    "\n",
    "print(cleaner_sentence, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Timothy', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "sent = \"Timothy is a natural when it comes to drawing\"\n",
    "sent_tokens = word_tokenize(sent)\n",
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP')]\n",
      "[('is', 'VBZ')]\n",
      "[('eating', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('delicious', 'JJ')]\n",
      "[('cake', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"John is eating a delicious cake\"\n",
    "sent_tokens2 = word_tokenize(sent2)\n",
    "for token in sent_tokens2:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', 'NN')]\n",
      "[('something', 'NN')]\n",
      "[('on', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('internet', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"Google something on the internet\" # Di sini kata Google-nya sebenarnya verb, tetapi mesin mendeteksinya sebagai noun.\n",
    "sent_tokens2 = word_tokenize(sent2)\n",
    "for token in sent_tokens2:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT')]\n",
      "[('public', 'NN')]\n",
      "[('seeks', 'NN')]\n",
      "[('the', 'DT')]\n",
      "[('government', 'NN')]\n",
      "[(\"'s\", 'POS')]\n",
      "[('direct', 'JJ')]\n",
      "[('response', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('five', 'CD')]\n",
      "[('major', 'JJ')]\n",
      "[('demands', 'NNS')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('people', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('rather', 'RB')]\n",
      "[('than', 'IN')]\n",
      "[('blaming', 'VBG')]\n",
      "[('the', 'DT')]\n",
      "[('civil', 'JJ')]\n",
      "[('movement', 'NN')]\n",
      "[('for', 'IN')]\n",
      "[('disturbing', 'VBG')]\n",
      "[('the', 'DT')]\n",
      "[('economy', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"The public seeks the government's direct response to the five major demands of the people, rather than blaming the civil movement for disturbing the economy\"\n",
    "sent_tokens2 = word_tokenize(sent2)\n",
    "for token in sent_tokens2:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    }
   ],
   "source": [
    "# Ingin mendeteksi nama orang, nama perusahaan, nama tempat, quantity, dan sebagainya.\n",
    "# Bisa dilakukan menggunakan bantuan POS tag.\n",
    "\n",
    "from nltk import ne_chunk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "NE_sent = \"The US President stays in the WHITE HOUSE\"\n",
    "NE_tokens = word_tokenize(NE_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_tags = nltk.pos_tag(NE_tokens) # Dikasih tag terlebih dahulu. Get POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY WHITE/NNP HOUSE/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE_NER=ne_chunk(NE_tags) # Chunk and show the POS Tags\n",
    "print(NE_NER)\n",
    "\n",
    "# S itu sentence\n",
    "# Di bawahnya ada POS tags\n",
    "# Yang White House sudah tepat, satu grup, tetapi US President belum dikenali sebagai satu grup. Mungkin pola DT-NNP-NNP\n",
    "# belum ada di data train-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  It/PRP\n",
      "  only/RB\n",
      "  worsened/VBD\n",
      "  after/IN\n",
      "  (GPE Hong/NNP Kong/NNP)\n",
      "  protesters/NNS\n",
      "  twice/RB\n",
      "  threw/VBD\n",
      "  the/DT\n",
      "  (GPE Chinese/JJ)\n",
      "  national/JJ\n",
      "  flag/NN\n",
      "  into/IN\n",
      "  (ORGANIZATION Victoria/NNP Harbour/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  major/JJ\n",
      "  shopping/NN\n",
      "  district/NN\n",
      "  of/IN\n",
      "  (PERSON Tsim/NNP Sha/NNP Tsui/NNP)\n",
      "  ,/,\n",
      "  provoking/VBG\n",
      "  fury/NN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  mainland/NN)\n"
     ]
    }
   ],
   "source": [
    "NE_sent = \"It only worsened after Hong Kong protesters twice threw the Chinese national flag into Victoria Harbour in the major shopping district of Tsim Sha Tsui, provoking fury on the mainland\"\n",
    "NE_tokens = word_tokenize(NE_sent)\n",
    "\n",
    "NE_tags = nltk.pos_tag(NE_tokens) # Dikasih tag terlebih dahulu. Get POS tags.\n",
    "\n",
    "NE_NER=ne_chunk(NE_tags) # Chunk and show the POS Tags\n",
    "print(NE_NER)\n",
    "\n",
    "# Coba deh kalo named entity-nya dibikin lowercase semua. Nanti hasilnya rada aneh muehehehe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m                         \u001b[0mbinary_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gswin32c.exe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gswin64c.exe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m                         \u001b[0menv_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m                     )\n\u001b[0;32m    799\u001b[0m                 ]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    694\u001b[0m     return next(\n\u001b[0;32m    695\u001b[0m         find_binary_iter(\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         )\n\u001b[0;32m    698\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \"\"\"\n\u001b[0;32m    679\u001b[0m     for file in find_file_iter(\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m     ):\n\u001b[0;32m    682\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n\\n  For more information on %s, see:\\n    <%s>'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', [('The', 'DT'), ('big', 'JJ'), ('cat', 'NN')]), ('ate', 'VBD'), Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('mouse', 'NN')]), ('who', 'WP'), ('was', 'VBD'), ('after', 'IN'), Tree('NP', [('fresh', 'JJ'), ('cheese', 'NN')])])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunking untuk memperoleh yang mana yang sekiranya named entity.\n",
    "# Picking up individual pieces of information (yang muncul secara berurutan) and grouping them into bigger pieces.\n",
    "\n",
    "new=\"The big cat ate the little mouse who was after fresh cheese\"\n",
    "\n",
    "new_tokens=nltk.pos_tag(word_tokenize(new))\n",
    "new_tokens\n",
    "\n",
    "grammar_np=r\"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser=nltk.RegexpParser(grammar_np)\n",
    "\n",
    "chunk_result=chunk_parser.parse(new_tokens)\n",
    "chunk_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1 0 0 1 1 0 0 0 0]\n",
      " [0 1 0 1 1 0 1 1 1 0 1 1 1 1]]\n",
      "{'all': 0, 'my': 8, 'cats': 2, 'in': 5, 'row': 9, 'when': 13, 'cat': 1, 'sits': 11, 'down': 3, 'she': 10, 'looks': 7, 'like': 6, 'furby': 4, 'toy': 12}\n"
     ]
    }
   ],
   "source": [
    "# Membuat data-data teks yang unstructured jadi berbentuk structured, disimpan dalam matriks.\\\n",
    "# Meng-generate hasil vektor dari kalimat yang di-input-kan.\n",
    "# Bukan berapa banyak kata-kata muncul, tetapi apakah kata-kata tersebut muncul dalam sebuah artikel atau tidak.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['All my cats in a row','When my cat sits down, she looks like a Furby toy!']\n",
    "# Masing-masing kata-kata diberi indeks.\n",
    "\n",
    "vectorizer = CountVectorizer() # Panjang vektor sesuai vocabulary.\n",
    "print(vectorizer.fit_transform(corpus).todense())\n",
    "print(vectorizer.vocabulary_) # Berasal dari kata-kata yang muncul di dalam corpus yang dimiliki. Automatis lowercase.\n",
    "# Ada 14 fitur.\n",
    "# Setiap baris merepresentasikan artikel/kalimat.\n",
    "# Menjelaskan maksud dari kalimat kepada mesin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
